{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GIepLGyHdZ1"
      },
      "source": [
        "# MTGBM Package Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jcqbK1cHi_O"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/antmachineintelligence/mtgbmcode.git\n",
        "\n",
        "%cd ./mtgbmcode/python-package/\n",
        "!python -m build\n",
        "\n",
        "%cd ./dist\n",
        "!pip install lightgbmmt-2.3.2-py3-none-any.whl --force-reinstall --no-deps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZdQ-YjaVrvj"
      },
      "source": [
        "# Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O42qJWBKFvbd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IecC2KbMVxa9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split,  KFold,StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder,  RobustScaler, MinMaxScaler\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve,log_loss, auc, precision_recall_curve, mean_absolute_error, mean_squared_error, f1_score,precision_recall_curve, mean_squared_error, average_precision_score,median_absolute_error, precision_score, f1_score, balanced_accuracy_score, accuracy_score, roc_auc_score, recall_score, r2_score\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import resample\n",
        "import skimage\n",
        "import scipy.stats as stat\n",
        "import lightgbm as lgb\n",
        "import lightgbmmt as lgbmmt\n",
        "from scipy.stats import norm, sem, t\n",
        "from scipy import stats\n",
        "from scipy.optimize import minimize\n",
        "import shap\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "import random\n",
        "import ipywidgets as widgets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygs_yMsBVy9j"
      },
      "source": [
        "# Model Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-_b8Vs2QwJ8"
      },
      "outputs": [],
      "source": [
        "def delong_roc_test(actual, preds_a, preds_b):\n",
        "    actual = np.array(actual, dtype=bool)\n",
        "    preds_a = np.array(preds_a, dtype=float)\n",
        "    preds_b = np.array(preds_b, dtype=float)\n",
        "\n",
        "    xa = preds_a[actual]\n",
        "    ya = preds_a[~actual]\n",
        "    ta1 = np.tile(xa, (len(ya), 1))\n",
        "    ta2 = np.tile(ya, (len(xa), 1)).T\n",
        "    xa_ya = (ta1 > ta2).astype(float)\n",
        "    xa_ya[ta1 == ta2] = 0.5\n",
        "    auc_a = np.mean(xa_ya)\n",
        "    va10 = np.mean(xa_ya, axis=0)\n",
        "    va01 = np.mean(xa_ya, axis=1)\n",
        "\n",
        "    xb = preds_b[actual]\n",
        "    yb = preds_b[~actual]\n",
        "    tb1 = np.tile(xb, (len(yb), 1))\n",
        "    tb2 = np.tile(yb, (len(xb), 1)).T\n",
        "    xb_yb = (tb1 > tb2).astype(float)\n",
        "    xb_yb[tb1 == tb2] = 0.5\n",
        "    auc_b = np.mean(xb_yb)\n",
        "    vb10 = np.mean(xb_yb, axis=0)\n",
        "    vb01 = np.mean(xb_yb, axis=1)\n",
        "\n",
        "    var_a = np.mean([(a - auc_a) * (b - auc_a) for a, b in zip(va10, va10)]) / (len(va10) - 1)\n",
        "    var_a += np.mean([(a - auc_a) * (b - auc_a) for a, b in zip(va01, va01)]) / (len(va01) - 1)\n",
        "\n",
        "    var_b = np.mean([(a - auc_b) * (b - auc_b) for a, b in zip(vb10, vb10)]) / (len(vb10) - 1)\n",
        "    var_b += np.mean([(a - auc_b) * (b - auc_b) for a, b in zip(vb01, vb01)]) / (len(vb01) - 1)\n",
        "\n",
        "    covar_ab = np.mean([(a - auc_a) * (b - auc_b) for a, b in zip(va10, vb10)]) / (len(va10) - 1)\n",
        "    covar_ab += np.mean([(a - auc_a) * (b - auc_b) for a, b in zip(va01, vb01)]) / (len(va01) - 1)\n",
        "\n",
        "    denominator = (var_a + var_b - 2 * covar_ab)\n",
        "    if denominator <= 0:\n",
        "        return 1.0\n",
        "\n",
        "    z = (auc_a - auc_b) / denominator ** 0.5\n",
        "    print(scipy.stats.norm.sf(abs(z) * 2))\n",
        "    return scipy.stats.norm.sf(abs(z) * 2)\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        bin_low, bin_high = bin_edges[i], bin_edges[i + 1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        plt.errorbar(\n",
        "            x, y, yerr=h, fmt='o-', color='tab:blue', ecolor='gray', capsize=4,\n",
        "            markersize=7, linewidth=2, label=None if i > 0 else \"Platt Calibration\"\n",
        "        )\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Platt-Scaled Calibration Curve with 95% CI (Bins: {n_bins})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def new_threshold(y_test, y_pred):\n",
        "    fpr, tpr, thvals = roc_curve(y_test, y_pred)\n",
        "    lb, ub = roc_ci(y_test, y_pred)\n",
        "    auroc = auc(fpr, tpr)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "    auprc = auc(recall, precision)\n",
        "    sensitivity_threshold = 0.9\n",
        "    valid_idx = np.where(tpr >= sensitivity_threshold)[0]\n",
        "\n",
        "    if sum(i > 0 for i in valid_idx) == 0:\n",
        "        raise ValueError(\"No thresholds found with sensitivity >= 0.90\")\n",
        "\n",
        "    youden_index = tpr[valid_idx] - fpr[valid_idx]\n",
        "    optimal_idx = np.argmax(youden_index)\n",
        "    optimal_threshold = thvals[valid_idx[optimal_idx]]\n",
        "\n",
        "    return optimal_threshold\n",
        "\n",
        "def roc_ci(y_true, y_pred):\n",
        "    total = len(y_true)\n",
        "    success = roc_auc_score(y_true, y_pred) * total\n",
        "    alpha = 0.05\n",
        "    lower = stats.beta.ppf(alpha / 2, success, total - success + 1)\n",
        "    upper = stats.beta.ppf(1 - alpha / 2, success + 1, total - success)\n",
        "    return lower, upper\n",
        "\n",
        "def calculate_auprc(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "    auprc = auc(recall, precision)\n",
        "    total = len(y_true)\n",
        "    success = auprc * total\n",
        "    alpha = 0.05\n",
        "    lower = stats.beta.ppf(alpha / 2, success, total - success + 1)\n",
        "    upper = stats.beta.ppf(1 - alpha / 2, success + 1, total - success)\n",
        "    return lower, upper\n",
        "\n",
        "def custom_sampling(y_true, y_pred, num_bootstrap=2000):\n",
        "    metric_values = []\n",
        "    bs = 0\n",
        "\n",
        "    while bs < num_bootstrap:\n",
        "        np.random.seed(bs)\n",
        "        sampled_indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
        "        sampled_y_true = y_true.iloc[sampled_indices]\n",
        "        sampled_y_pred = y_pred[sampled_indices]\n",
        "\n",
        "        unique_classes = np.unique(sampled_y_true)\n",
        "\n",
        "        if len(unique_classes) > 1:\n",
        "            metric_values.append((sampled_y_true, sampled_y_pred))\n",
        "            bs += 1\n",
        "\n",
        "    return metric_values\n",
        "\n",
        "def calculate_ci(metric_values, metric_fn, best_thres=0):\n",
        "    if best_thres > 0:\n",
        "        metric_values = [metric_fn(sample_y_true, sample_y_pred > best_thres) for sample_y_true, sample_y_pred in metric_values]\n",
        "    else:\n",
        "        metric_values = [metric_fn(sample_y_true, sample_y_pred) for sample_y_true, sample_y_pred in metric_values]\n",
        "    lower_bound = np.percentile(metric_values, 2.5)\n",
        "    upper_bound = np.percentile(metric_values, 97.5)\n",
        "    mean = np.mean(metric_values)\n",
        "    return mean, lower_bound, upper_bound\n",
        "\n",
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "def auc_plot(y_test, y_pred, name, best_threshold):\n",
        "    fpr, tpr, thvals = roc_curve(y_test, y_pred)\n",
        "    lb_auroc, ub_auroc = roc_ci(y_test, y_pred)\n",
        "    auroc = auc(fpr, tpr)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "    auprc = auc(recall, precision)\n",
        "    lb_auprc, ub_auprc = calculate_auprc(y_test, y_pred)\n",
        "    num_bootstrap = 2000\n",
        "    metric_val = custom_sampling(y_test, y_pred, num_bootstrap=num_bootstrap)\n",
        "    y_pred = y_pred > best_threshold\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    sens, sens_lb, sens_ub = calculate_ci(metric_val, recall_score, best_thres=best_threshold)\n",
        "    spec, spec_lb, spec_ub = calculate_ci(metric_val, specificity_score, best_thres=best_threshold)\n",
        "    prec, prec_lb, prec_ub = calculate_ci(metric_val, precision_score, best_thres=best_threshold)\n",
        "    acc, acc_lb, acc_ub = calculate_ci(metric_val, balanced_accuracy_score, best_thres=best_threshold)\n",
        "    f1, f1_lb, f1_ub = calculate_ci(metric_val, f1_score, best_thres=best_threshold)\n",
        "\n",
        "    val = pd.DataFrame({\n",
        "        'Threshold': best_threshold,\n",
        "        'auroc': (' {:.3f} ({:.3f} - {:.3f})'.format(auroc, lb_auroc, ub_auroc)),\n",
        "        'auprc': (' {:.3f} ({:.3f} - {:.3f})'.format(auprc, lb_auprc, ub_auprc)),\n",
        "        'Sensitivity (95% CI)': (' {:.3f} ({:.3f} - {:.3f})'.format(sens, sens_lb, sens_ub)),\n",
        "        'Specificity (95% CI)': (' {:.3f} ({:.3f} - {:.3f})'.format(spec, spec_lb, spec_ub)),\n",
        "        'Precision (95% CI)': (' {:.3f} ({:.3f} - {:.3f})'.format(prec, prec_lb, prec_ub)),\n",
        "        'F1 score (95% CI)': (' {:.3f} ({:.3f} - {:.3f})'.format(f1, f1_lb, f1_ub)),\n",
        "        'Accuracy (95% CI)': (' {:.3f} ({:.3f} - {:.3f})'.format(acc, acc_lb, acc_ub)),\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn,\n",
        "        'TP': tp\n",
        "    }, index=[name])\n",
        "\n",
        "    return val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cecbd85-34a1-4517-b6fc-f4c34f0c7daa"
      },
      "source": [
        "# 1. Sample Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cf2f8ba"
      },
      "source": [
        "#### 1.1 Train Test Set Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5xZq2Sfk3mZ"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "FOLDS_NUM = 5\n",
        "num_labels=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIcRWxQnKH9u"
      },
      "outputs": [],
      "source": [
        "def make_dataset0(data_a, data_ak, data_an, test_size=0.2, seed=SEED):\n",
        "    data_a_grouped = data_a.groupby('hid')\n",
        "    group_aki_mean = data_a_grouped['total_aki'].mean().reset_index()\n",
        "    group_aki_mean.columns = ['hid', 'total_aki_mean']\n",
        "    group_aki_mean['total_aki_mean'] = group_aki_mean['total_aki_mean'].apply(lambda x: 0.5 if x < 0.5 else x)\n",
        "    train_hids, test_hids = train_test_split(\n",
        "        group_aki_mean, test_size=test_size, random_state=seed, stratify=group_aki_mean['total_aki_mean'])\n",
        "\n",
        "    train_data_list = [data_a_grouped.get_group(hid) for hid in train_hids['hid']]\n",
        "    test_data_list = [data_a_grouped.get_group(hid) for hid in test_hids['hid']]\n",
        "    data_a_train = pd.concat(train_data_list)\n",
        "    data_a_test = pd.concat(test_data_list)\n",
        "\n",
        "    label_col_all = ['total_aki', 'hos', 'final_prf', 'inhos_mortality']\n",
        "    label_col_a = ['total_aki', 'hos', 'final_prf', 'inhos_mortality']\n",
        "    aX_train, aY_all_train = data_a_train.loc[:, ~data_a_train.columns.isin(label_col_all)], data_a_train[label_col_all]\n",
        "    aX_test, aY_all_test = data_a_test.loc[:, ~data_a_test.columns.isin(label_col_all)], data_a_test[label_col_all]\n",
        "    aya_train = aY_all_train[label_col_a]\n",
        "    aya_test = aY_all_test[label_col_a]\n",
        "\n",
        "    aX_kmc, aY_all_kmc = data_ak.loc[:, ~data_ak.columns.isin(label_col_all)], data_ak[label_col_all]\n",
        "    aya_kmc = aY_all_kmc[label_col_a]\n",
        "    aX_nowon, aY_all_nowon = data_an.loc[:, ~data_an.columns.isin(label_col_all)], data_an[label_col_all]\n",
        "    aya_nowon = aY_all_nowon[label_col_a]\n",
        "\n",
        "    ft_ii = ['asa', 'sex', 'pcr', 'age', 'bmi', 'total_em', 'phb', 'pwbc', 'pplt', 'pbun', 'palb', 'pgot', 'pgpt', 'pna', 'pk', 'pglu', 'pptinr', 'andur', 'dept_GS', 'dept_NS', 'dept_OG', 'dept_OL', 'dept_OS', 'dept_Others', 'dept_PS', 'dept_TS', 'dept_UR']\n",
        "\n",
        "    aX_kmc['hid'] = 99999999\n",
        "    aX_nowon['hid'] = 88888888\n",
        "\n",
        "    tr_asa = aX_train[['caseid', 'asa']]\n",
        "    te_asa = aX_test[['caseid', 'asa']]\n",
        "    kmc_asa = aX_kmc[['caseid', 'asa']]\n",
        "    nowon_asa = aX_nowon[['caseid', 'asa']]\n",
        "\n",
        "    aX_train_key = aX_train[['caseid', 'hid']]\n",
        "    aX_test_key = aX_test[['caseid', 'hid']]\n",
        "    aX_kmc_key = aX_kmc[['caseid', 'hid']]\n",
        "    aX_nowon_key = aX_nowon[['caseid', 'hid']]\n",
        "\n",
        "    aX_train = aX_train[ft_ii]\n",
        "    aX_test = aX_test[ft_ii]\n",
        "    aX_kmc = aX_kmc[ft_ii]\n",
        "    aX_nowon = aX_nowon[ft_ii]\n",
        "\n",
        "    imp = IterativeImputer(max_iter=50, random_state=seed)\n",
        "    aX_train = imp.fit_transform(aX_train)\n",
        "    aX_test = imp.transform(aX_test)\n",
        "    aX_kmc = imp.transform(aX_kmc)\n",
        "    aX_nowon = imp.transform(aX_nowon)\n",
        "\n",
        "    aX_train = pd.DataFrame(data=aX_train, columns=ft_ii, index=aX_train_key.index)\n",
        "    aX_test = pd.DataFrame(data=aX_test, columns=ft_ii, index=aX_test_key.index)\n",
        "    aX_kmc = pd.DataFrame(data=aX_kmc, columns=ft_ii, index=aX_kmc_key.index)\n",
        "    aX_nowon = pd.DataFrame(data=aX_nowon, columns=ft_ii, index=aX_nowon_key.index)\n",
        "\n",
        "    aX_train = pd.concat([aX_train_key, aX_train], axis=1)\n",
        "    aX_test = pd.concat([aX_test_key, aX_test], axis=1)\n",
        "    aX_kmc = pd.concat([aX_kmc_key, aX_kmc], axis=1)\n",
        "    aX_nowon = pd.concat([aX_nowon_key, aX_nowon], axis=1)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    aya_train['hos_org'] = aya_train['hos'].copy()\n",
        "    aya_test['hos_org'] = aya_test['hos'].copy()\n",
        "    aya_kmc['hos_org'] = aya_kmc['hos'].copy()\n",
        "    aya_nowon['hos_org'] = aya_nowon['hos'].copy()\n",
        "\n",
        "    aya_train['hos'] = scaler.fit_transform(aya_train[['hos']])\n",
        "    aya_test['hos'] = scaler.transform(aya_test[['hos']])\n",
        "    aya_kmc['hos'] = scaler.transform(aya_kmc[['hos']])\n",
        "    aya_nowon['hos'] = scaler.transform(aya_nowon[['hos']])\n",
        "\n",
        "    return aX_train, aya_train, aX_test, aya_test, aX_kmc, aya_kmc, tr_asa, te_asa, kmc_asa, aX_nowon, aya_nowon, nowon_asa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTGpZhD6xw-I"
      },
      "outputs": [],
      "source": [
        "def make_dataset1(data_a, data_ak, data_an, test_size=0.2, seed=SEED):\n",
        "    data_a_grouped = data_a.groupby('hid')\n",
        "    group_mean = data_a_grouped[['total_aki', 'final_prf', 'inhos_mortality']].mean().reset_index()\n",
        "    for col in ['total_aki', 'final_prf', 'inhos_mortality']:\n",
        "        group_mean[col] = group_mean[col].apply(lambda x: 0.5 if x < 0.5 else 1)\n",
        "    group_mean['stratify_label'] = (\n",
        "        group_mean['total_aki'].astype(str) + '_' +\n",
        "        group_mean['final_prf'].astype(str) + '_' +\n",
        "        group_mean['inhos_mortality'].astype(str)\n",
        "    )\n",
        "    train_hids, test_hids = train_test_split(\n",
        "        group_mean, test_size=test_size, random_state=seed, stratify=group_mean['stratify_label']\n",
        "    )\n",
        "    train_data_list = [data_a_grouped.get_group(hid) for hid in train_hids['hid']]\n",
        "    test_data_list = [data_a_grouped.get_group(hid) for hid in test_hids['hid']]\n",
        "    data_a_train = pd.concat(train_data_list)\n",
        "    data_a_test = pd.concat(test_data_list)\n",
        "\n",
        "    label_col_all = ['total_aki', 'hos', 'final_prf', 'inhos_mortality']\n",
        "    label_col_a = ['total_aki', 'hos', 'final_prf', 'inhos_mortality']\n",
        "    aX_train, aY_all_train = data_a_train.loc[:, ~data_a_train.columns.isin(label_col_all)], data_a_train[label_col_all]\n",
        "    aX_test, aY_all_test = data_a_test.loc[:, ~data_a_test.columns.isin(label_col_all)], data_a_test[label_col_all]\n",
        "    aya_train = aY_all_train[label_col_a]\n",
        "    aya_test = aY_all_test[label_col_a]\n",
        "\n",
        "    aX_kmc, aY_all_kmc = data_ak.loc[:, ~data_ak.columns.isin(label_col_all)], data_ak[label_col_all]\n",
        "    aya_kmc = aY_all_kmc[label_col_a]\n",
        "    aX_nowon, aY_all_nowon = data_an.loc[:, ~data_an.columns.isin(label_col_all)], data_an[label_col_all]\n",
        "    aya_nowon = aY_all_nowon[label_col_a]\n",
        "\n",
        "    ft_ii = ['asa', 'sex', 'pcr', 'age', 'bmi', 'total_em', 'phb', 'pwbc', 'pplt', 'pbun', 'palb', 'pgot', 'pgpt', 'pna', 'pk', 'pglu', 'pptinr', 'andur', 'dept_GS', 'dept_NS', 'dept_OG', 'dept_OL', 'dept_OS', 'dept_Others', 'dept_PS', 'dept_TS', 'dept_UR']\n",
        "\n",
        "    aX_kmc['hid'] = 99999999\n",
        "    aX_nowon['hid'] = 88888888\n",
        "\n",
        "    tr_asa = aX_train[['caseid', 'asa']]\n",
        "    te_asa = aX_test[['caseid', 'asa']]\n",
        "    kmc_asa = aX_kmc[['caseid', 'asa']]\n",
        "    nowon_asa = aX_nowon[['caseid', 'asa']]\n",
        "\n",
        "    aX_train_key = aX_train[['caseid', 'hid']]\n",
        "    aX_test_key = aX_test[['caseid', 'hid']]\n",
        "    aX_kmc_key = aX_kmc[['caseid', 'hid']]\n",
        "    aX_nowon_key = aX_nowon[['caseid', 'hid']]\n",
        "\n",
        "    aX_train = aX_train[ft_ii]\n",
        "    aX_test = aX_test[ft_ii]\n",
        "    aX_kmc = aX_kmc[ft_ii]\n",
        "    aX_nowon = aX_nowon[ft_ii]\n",
        "\n",
        "    imp = IterativeImputer(max_iter=50, random_state=seed)\n",
        "    aX_train = imp.fit_transform(aX_train)\n",
        "    aX_test = imp.transform(aX_test)\n",
        "    aX_kmc = imp.transform(aX_kmc)\n",
        "    aX_nowon = imp.transform(aX_nowon)\n",
        "\n",
        "    aX_train = pd.DataFrame(data=aX_train, columns=ft_ii, index=aX_train_key.index)\n",
        "    aX_test = pd.DataFrame(data=aX_test, columns=ft_ii, index=aX_test_key.index)\n",
        "    aX_kmc = pd.DataFrame(data=aX_kmc, columns=ft_ii, index=aX_kmc_key.index)\n",
        "    aX_nowon = pd.DataFrame(data=aX_nowon, columns=ft_ii, index=aX_nowon_key.index)\n",
        "\n",
        "    aX_train = pd.concat([aX_train_key, aX_train], axis=1)\n",
        "    aX_test = pd.concat([aX_test_key, aX_test], axis=1)\n",
        "    aX_kmc = pd.concat([aX_kmc_key, aX_kmc], axis=1)\n",
        "    aX_nowon = pd.concat([aX_nowon_key, aX_nowon], axis=1)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    aya_train['hos_org'] = aya_train['hos'].copy()\n",
        "    aya_test['hos_org'] = aya_test['hos'].copy()\n",
        "    aya_kmc['hos_org'] = aya_kmc['hos'].copy()\n",
        "    aya_nowon['hos_org'] = aya_nowon['hos'].copy()\n",
        "\n",
        "    aya_train['hos'] = scaler.fit_transform(aya_train[['hos']])\n",
        "    aya_test['hos'] = scaler.transform(aya_test[['hos']])\n",
        "    aya_kmc['hos'] = scaler.transform(aya_kmc[['hos']])\n",
        "    aya_nowon['hos'] = scaler.transform(aya_nowon[['hos']])\n",
        "\n",
        "    return aX_train, aya_train, aX_test, aya_test, aX_kmc, aya_kmc, tr_asa, te_asa, kmc_asa, aX_nowon, aya_nowon, nowon_asa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ab8e001-540b-4b0d-9aa0-42e752272257"
      },
      "outputs": [],
      "source": [
        "#data load\n",
        "df0 = pd.read_csv('SNUH_data.csv')\n",
        "kmc0 = pd.read_csv('KMC_data.csv')\n",
        "nowon0 = pd.read_csv('Nowon_data.csv')\n",
        "\n",
        "print('1.load new snu:',df0.shape)\n",
        "print('1.load new kmc:',kmc0.shape)\n",
        "print('1.load new nowon:',nowon0.shape)\n",
        "\n",
        "df0['asa'] = (df0[['asa_1', 'asa_2', 'asa_3', 'asa_4', 'asa_5']] * [1, 2, 3, 4, 5]).sum(axis=1)\n",
        "kmc0['asa'] = (kmc0[['asa_1', 'asa_2', 'asa_3', 'asa_4', 'asa_5']] * [1, 2, 3, 4, 5]).sum(axis=1)\n",
        "nowon0['asa'] = (nowon0[['asa_1', 'asa_2', 'asa_3', 'asa_4', 'asa_5']] * [1, 2, 3, 4, 5]).sum(axis=1)\n",
        "\n",
        "data0=df0.copy()\n",
        "data_k0=kmc0.copy()\n",
        "data_n0=nowon0.copy()\n",
        "\n",
        "adtrain0, aya_train0, adtest0, aya_test0, adkmc0, aya_kmc0, asa_train0, asa_test0, asa_kmc0, adnowon0, aya_nowon0, asa_nowon0 = make_dataset0(data0, data_k0, data_n0)\n",
        "\n",
        "print('adtrain0:' , adtrain0.shape)\n",
        "print('adtest0:' , adtest0.shape)\n",
        "print('kmc0:' , adkmc0.shape)\n",
        "print('nowon0:' , adnowon0.shape)\n",
        "print('asa_train0:' , asa_train0.shape)\n",
        "print('asa_test0:' , asa_test0.shape)\n",
        "print('asa_kmc0:' , asa_kmc0.shape)\n",
        "print('asa_nowon0:' , asa_nowon0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc442269-acdd-4ddd-8357-37745b3da956"
      },
      "outputs": [],
      "source": [
        "snu_train_hos0 = pd.DataFrame()\n",
        "snu_train_hos0['hos_org'] = aya_train0['hos_org']\n",
        "aya_train0.drop('hos_org', axis=1, inplace=True)\n",
        "\n",
        "snu_test_hos0 = pd.DataFrame()\n",
        "snu_test_hos0['hos_org'] = aya_test0['hos_org']\n",
        "aya_test0.drop('hos_org', axis=1, inplace=True)\n",
        "\n",
        "kmc_hos0 = pd.DataFrame()\n",
        "kmc_hos0['hos_org'] = aya_kmc0['hos_org']\n",
        "aya_kmc0.drop('hos_org', axis=1, inplace=True)\n",
        "\n",
        "nowon_hos0 = pd.DataFrame()\n",
        "nowon_hos0['hos_org'] = aya_nowon0['hos_org']\n",
        "aya_nowon0.drop('hos_org', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2d892b4"
      },
      "source": [
        "#### 1.2 5-fold Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b70b6424"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pickle\n",
        "\n",
        "seed = SEED\n",
        "np.random.seed(seed)\n",
        "\n",
        "data = pd.concat([adtrain0.reset_index(drop=True), aya_train0.reset_index(drop=True)], axis=1)\n",
        "\n",
        "group_mean = data.groupby('hid')[['total_aki', 'final_prf', 'inhos_mortality']].mean().reset_index()\n",
        "\n",
        "for col in ['total_aki', 'final_prf', 'inhos_mortality']:\n",
        "    group_mean[col] = group_mean[col].apply(lambda x: 0.5 if x < 0.5 else 1)\n",
        "\n",
        "group_mean['stratify'] = (\n",
        "    group_mean['total_aki'].astype(str) + '_' +\n",
        "    group_mean['final_prf'].astype(str) + '_' +\n",
        "    group_mean['inhos_mortality'].astype(str)\n",
        ")\n",
        "\n",
        "remaining_hids = group_mean\n",
        "\n",
        "folds = [[] for _ in range(5)]\n",
        "test_sizes = [0.2, 0.25, 0.33, 0.5]\n",
        "target_fold_size = len(data) // 5\n",
        "\n",
        "for i, test_size in enumerate(test_sizes):\n",
        "    print(f\"fold {i+1} generated\")\n",
        "\n",
        "    remaining_hids, test_hids = train_test_split(\n",
        "        remaining_hids, test_size=test_size, random_state=seed, stratify=remaining_hids['stratify'])\n",
        "    fold_hids = test_hids['hid'].tolist()\n",
        "\n",
        "    fold_data = data[data['hid'].isin(fold_hids)]\n",
        "    while len(fold_data) > target_fold_size:\n",
        "        extra_hid = fold_data['hid'].value_counts().idxmin()\n",
        "        fold_data = fold_data[fold_data['hid'] != extra_hid]\n",
        "        extra_row = group_mean[group_mean['hid'] == extra_hid]\n",
        "        remaining_hids = pd.concat([remaining_hids, extra_row])\n",
        "        print(f\"Adjusting fold {i+1} down: {len(fold_data)} remaining, target {target_fold_size}\")\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    while len(fold_data) < target_fold_size:\n",
        "        extra_hid = remaining_hids['hid'].value_counts().idxmin()\n",
        "        remaining_hids = remaining_hids[remaining_hids['hid'] != extra_hid]\n",
        "        extra_row = data[data['hid'] == extra_hid]\n",
        "        fold_data = pd.concat([fold_data, extra_row])\n",
        "        print(f\"Adjusting fold {i+1} up: {len(fold_data)} current, target {target_fold_size}\")\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    folds[i] = fold_data['hid'].tolist()\n",
        "\n",
        "folds[4] = remaining_hids['hid'].tolist()\n",
        "\n",
        "data_folds = [data[data['hid'].isin(fold)] for fold in folds]\n",
        "fold_sizes = [len(fold_data) for fold_data in data_folds]\n",
        "\n",
        "for i, fold_data in enumerate(data_folds):\n",
        "    with open(f'fold_{i+1}.pkl', 'wb') as f:\n",
        "        pickle.dump(fold_data, f)\n",
        "    print(f\"Fold {i+1} saved to fold_{i+1}.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "684e91fb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pickle\n",
        "\n",
        "loaded_folds = []\n",
        "for i in range(5):\n",
        "    with open(f'fold_{i+1}.pkl', 'rb') as f:\n",
        "        fold_data = pickle.load(f)\n",
        "        loaded_folds.append(fold_data)\n",
        "    print(f\"Fold {i+1} 로드 완료: fold_{i+1}.pkl\")\n",
        "\n",
        "loaded_fold_sizes = [len(fold_data) for fold_data in loaded_folds]\n",
        "print(\"Loaded fold sizes:\", loaded_fold_sizes)\n",
        "\n",
        "num_patients_list = []\n",
        "num_aki_1_list = []\n",
        "num_final_prf_1_list = []\n",
        "num_inhos_mortality_1_list = []\n",
        "hos_mean_list = []\n",
        "\n",
        "for i, fold_data in enumerate(loaded_folds):\n",
        "    num_patients = fold_data['hid'].nunique()\n",
        "    num_aki_1 = fold_data[fold_data['total_aki'] == 1].shape[0]\n",
        "    num_final_prf_1 = fold_data[fold_data['final_prf'] == 1].shape[0]\n",
        "    num_inhos_mortality_1 = fold_data[fold_data['inhos_mortality'] == 1].shape[0]\n",
        "    hos_mean = fold_data['hos'].mean()\n",
        "\n",
        "    num_patients_list.append(num_patients)\n",
        "    num_aki_1_list.append(num_aki_1)\n",
        "    num_final_prf_1_list.append(num_final_prf_1)\n",
        "    num_inhos_mortality_1_list.append(num_inhos_mortality_1)\n",
        "    hos_mean_list.append(hos_mean)\n",
        "\n",
        "    print(f\"Fold {i+1}: {num_patients} patients, {num_aki_1} total_aki = 1, {num_final_prf_1} final_prf = 1, {num_inhos_mortality_1} inhos_mortality = 1, hos mean = {hos_mean}\")\n",
        "\n",
        "fold_data_summary = [\n",
        "    {\n",
        "        \"Fold\": f\"Fold {i+1}\",\n",
        "        \"Total Patients\": num_patients_list[i],\n",
        "        \"Total AKI = 1\": num_aki_1_list[i],\n",
        "        \"Total Final PRF = 1\": num_final_prf_1_list[i],\n",
        "        \"Total Inhos Mortality = 1\": num_inhos_mortality_1_list[i],\n",
        "        \"Hos Mean\": hos_mean_list[i],\n",
        "        \"Fold Size\": loaded_fold_sizes[i]\n",
        "    }\n",
        "    for i in range(5)\n",
        "]\n",
        "\n",
        "fold_summary_df = pd.DataFrame(fold_data_summary)\n",
        "\n",
        "fold_summary_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1291a80"
      },
      "outputs": [],
      "source": [
        "feature_columns = adtrain0.columns\n",
        "target_columns = aya_train0.columns\n",
        "\n",
        "folds_features = []\n",
        "folds_targets = []\n",
        "\n",
        "for i, fold_data in enumerate(loaded_folds):\n",
        "    features = fold_data[feature_columns]\n",
        "    targets = fold_data[target_columns]\n",
        "\n",
        "    folds_features.append(features)\n",
        "    folds_targets.append(targets)\n",
        "\n",
        "    print(f\"Fold {i+1} features and targets separated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# features selected by BorutaSHAP\n",
        "# acute kidney injury\n",
        "s10 = ['dept_OS', 'asa', 'phb', 'dept_NS', 'andur', 'palb', 'bmi', 'pcr', 'sex', 'age'] \n",
        "\n",
        "\n",
        "# postoperative respiratory failure\n",
        "s30 = ['dept_OS', 'asa', 'pwbc', 'andur', 'palb', 'dept_OGUR', 'age'] \n",
        "\n",
        "# inhospital mortality \n",
        "s40 = ['pgot', 'asa', 'pplt', 'pwbc', 'palb', 'pptinr', 'pglu'] \n",
        "\n",
        "# uniton set of selected features\n",
        "ft0 = ['age', 'andur', 'asa', 'bmi', 'dept_NS',  'dept_OGUR', 'dept_OS', 'palb', 'pcr', 'phb',  'pgot', 'pglu', 'pplt', 'pptinr', 'pwbc', 'sex'] \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c378350-a259-4e1c-b973-53d29a4e1aea"
      },
      "source": [
        "# 3. Single Light GBM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f4e83fb"
      },
      "outputs": [],
      "source": [
        "binary_params = {\n",
        "    'objective': 'binary',\n",
        "    'device': \"gpu\",\n",
        "    'metric': 'auc',\n",
        "    'boosting': 'gbdt',\n",
        "    'max_depth': 16,\n",
        "    'learning_rate': 0.01,\n",
        "    'bagging_fraction': 0.7,\n",
        "    'feature_fraction': 0.7,\n",
        "    'verbosity': -1,\n",
        "    'lambda_l1': 0.7,\n",
        "    'lambda_l2': 0.7,\n",
        "    'num_leaves': 50,\n",
        "    'min_data_in_leaf': 40,\n",
        "    'metric_freq': 9,\n",
        "    'data_random_seed': SEED,\n",
        "    'num_threads': -1,\n",
        "    'num_boost_round': 600\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afb85676-ae80-4559-8838-ad2de682f640"
      },
      "outputs": [],
      "source": [
        "def single_lgb_fun(folds_features, folds_targets, features, target, dtest, y1_test, params, cate):\n",
        "    foldsn = FOLDS_NUM\n",
        "    y_singlelgb = np.zeros(dtest.shape[0])\n",
        "    best_thresholds = 0.0\n",
        "\n",
        "    for i in range(foldsn):\n",
        "        X_vl, y_vl = folds_features[i][features], folds_targets[i][target]\n",
        "        X_tr = pd.concat([folds_features[j] for j in range(foldsn) if j != i], axis=0)[features]\n",
        "        y_tr = pd.concat([folds_targets[j] for j in range(foldsn) if j != i], axis=0)[target]\n",
        "\n",
        "        k_train = lgb.Dataset(X_tr, y_tr, categorical_feature=cate)\n",
        "        k_valid = lgb.Dataset(X_vl, y_vl, categorical_feature=cate)\n",
        "        watchlist = [k_valid]\n",
        "        y_oof = np.zeros(X_vl.shape[0])\n",
        "\n",
        "        singlelgb_model = lgb.train(\n",
        "            params=params,\n",
        "            train_set=k_train,\n",
        "            valid_sets=watchlist\n",
        "        )\n",
        "\n",
        "        y_pred_train = singlelgb_model.predict(X_vl)\n",
        "        y_oof = y_pred_train\n",
        "        print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    dtrain = pd.concat([folds_features[j] for j in range(foldsn)], axis=0)[features]\n",
        "    y1_train = pd.concat([folds_targets[j] for j in range(foldsn)], axis=0)[target]\n",
        "    k_train = lgb.Dataset(dtrain, y1_train, categorical_feature=cate)\n",
        "\n",
        "    singlelgb_model = lgb.train(\n",
        "        params=params,\n",
        "        train_set=k_train\n",
        "    )\n",
        "\n",
        "    forthval = singlelgb_model.predict(dtrain)\n",
        "    best_thresholds = new_threshold(y1_train, forthval)\n",
        "    y_singlelgb = singlelgb_model.predict(dtest)\n",
        "\n",
        "    return y_singlelgb, singlelgb_model, best_thresholds, forthval, y1_train\n",
        "\n",
        "def single_lgb_kmc(single_model_aki, dkmc, y1_kmc):\n",
        "    kmc_tmp = single_model_aki.predict(dkmc)\n",
        "    return kmc_tmp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87dae4b8"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame(columns =['Threshold', 'auroc',\t'auprc',\t'Sensitivity (95% CI)',\t'Specificity (95% CI)',\t'Precision (95% CI)',\n",
        "                                'F1 score (95% CI)',\t'Accuracy (95% CI)', 'TN', 'FP', 'FN','TP'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vmLV9x8KOr4"
      },
      "outputs": [],
      "source": [
        "#Single aki\n",
        "cate = []\n",
        "target = 'total_aki'\n",
        "single_aki, single_model_aki, s_thold, forthval, y1_train = single_lgb_fun(folds_features, folds_targets, s10, target, adtest0[s10],\n",
        "                                                      aya_test0[target], binary_params, cate )\n",
        "\n",
        "aya_nowon_pred =single_lgb_kmc(single_model_aki, adnowon0[s10], s_thold )\n",
        "aya_kmc_pred =single_lgb_kmc(single_model_aki, adkmc0[s10], s_thold )\n",
        "val_single_1 = auc_plot(aya_test0.iloc[:, [0]], single_aki, 'single_total_aki_snu',  s_thold)\n",
        "val_single_1_n = auc_plot(aya_nowon0.iloc[:, [0]], aya_nowon_pred, 'single_total_aki_nowon', s_thold)\n",
        "val_single_1_k = auc_plot(aya_kmc0.iloc[:, [0]], aya_kmc_pred, 'single_total_aki_kmc', s_thold)\n",
        "result = pd.concat([result, val_single_1])\n",
        "result = pd.concat([result, val_single_1_n])\n",
        "result = pd.concat([result, val_single_1_k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPvYcByj6Hnr"
      },
      "outputs": [],
      "source": [
        "!pip install ml_insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pl1xN4AyZnu"
      },
      "outputs": [],
      "source": [
        "# Spline Calibration for single AKI\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve\n",
        "import ml_insights as mli\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95, prefix=None):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        bin_low, bin_high = bin_edges[i], bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {n_bins})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if prefix is not None:\n",
        "        plt.savefig(f\"{prefix}_calibration_curve.png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_single_aki = splinecalib.predict(single_aki)\n",
        "calibrated_aya_nowon_pred = splinecalib.predict(aya_nowon_pred)\n",
        "calibrated_aya_kmc_pred = splinecalib.predict(aya_kmc_pred)\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test0.iloc[:, [0]].to_numpy().flatten(), calibrated_single_aki, prefix=\"single_aki_snuh\")\n",
        "plot_calibration_curve_with_ci2(aya_nowon0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_nowon_pred, prefix=\"single_aki_nowon\")\n",
        "plot_calibration_curve_with_ci2(aya_kmc0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_kmc_pred, prefix=\"single_aki_kmc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb04f66b-e12c-4e38-94f6-ab5faa1fe67b"
      },
      "outputs": [],
      "source": [
        "# snu single final_prf\n",
        "cate = []\n",
        "\n",
        "target='final_prf'\n",
        "single_prf, single_model_prf, s3_thold, forthval, y1_train = single_lgb_fun(folds_features,  folds_targets, s30, target, adtest0[s30],\n",
        "                                                       aya_test0['final_prf'], binary_params, cate )\n",
        "aya_nowon_pred3 =single_lgb_kmc(single_model_prf, adnowon0[s30], s3_thold )\n",
        "aya_kmc_pred3 =single_lgb_kmc(single_model_prf, adkmc0[s30], s3_thold )\n",
        "val_single_3 = auc_plot(aya_test0.iloc[:, [2]], single_prf,  'single_prf_snu', s3_thold)\n",
        "val_single_3_n =auc_plot(aya_nowon0.iloc[:, [2]], aya_nowon_pred3,  'single_prf_nowon', s3_thold)\n",
        "val_single_3_k =auc_plot(aya_kmc0.iloc[:, [2]], aya_kmc_pred3, 'single_prf_kmc', s3_thold)\n",
        "result = pd.concat([result, val_single_3])\n",
        "result = pd.concat([result, val_single_3_n])\n",
        "result = pd.concat([result, val_single_3_k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnxSOAD50x4J"
      },
      "outputs": [],
      "source": [
        "# spline calibration for single PRF\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95, prefix=None):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        bin_low, bin_high = bin_edges[i], bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {n_bins})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if prefix is not None:\n",
        "        plt.savefig(f\"{prefix}_calibration_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_single_prf = splinecalib.predict(single_prf)\n",
        "calibrated_aya_nowon_pred3 = splinecalib.predict(aya_nowon_pred3)\n",
        "calibrated_aya_kmc_pred3 = splinecalib.predict(aya_kmc_pred3)\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test0.iloc[:, [0]].to_numpy().flatten(), calibrated_single_prf, prefix=\"single_prf_snuh\")\n",
        "plot_calibration_curve_with_ci2(aya_nowon0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_nowon_pred3, prefix=\"single_prf_nowon\")\n",
        "plot_calibration_curve_with_ci2(aya_kmc0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_kmc_pred3, prefix=\"single_prf_kmc\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5ad3d66-6744-4af0-94a2-d6fd1338d43a"
      },
      "outputs": [],
      "source": [
        "# snu single inhos_mortality\n",
        "cate = []\n",
        "\n",
        "target='inhos_mortality'\n",
        "single_inhos, single_model_inhos, s4_thold, forthval, y1_train= single_lgb_fun(folds_features,  folds_targets, s40, target,  adtest0[s40],\n",
        "                                                           aya_test0['inhos_mortality'], binary_params,  cate )\n",
        "aya_nowon_pred4 =single_lgb_kmc(single_model_inhos, adnowon0[s40], s4_thold )\n",
        "aya_kmc_pred4 =single_lgb_kmc(single_model_inhos, adkmc0[s40], s4_thold )\n",
        "val_single_4 = auc_plot(aya_test0.iloc[:, [3]], single_inhos,  'single_inhos_snu', s4_thold)\n",
        "val_single_4_n =auc_plot(aya_nowon0.iloc[:, [3]], aya_nowon_pred4,  'single_inhos_nowon', s4_thold)\n",
        "val_single_4_k =auc_plot(aya_kmc0.iloc[:, [3]], aya_kmc_pred4, 'single_inhos_kmc', s4_thold)\n",
        "result = pd.concat([result, val_single_4])\n",
        "result = pd.concat([result, val_single_4_n])\n",
        "result = pd.concat([result, val_single_4_k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIBzX00p4XiC"
      },
      "outputs": [],
      "source": [
        "# Spline calibration for single inhos mortality\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95, prefix=None):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        bin_low, bin_high = bin_edges[i], bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {n_bins})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if prefix is not None:\n",
        "        plt.savefig(f\"{prefix}_calibration_curve.png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_single_inhos = splinecalib.predict(single_inhos)\n",
        "calibrated_aya_nowon_pred4 = splinecalib.predict(aya_nowon_pred4)\n",
        "calibrated_aya_kmc_pred4 = splinecalib.predict(aya_kmc_pred4)\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test0.iloc[:, [0]].to_numpy().flatten(), calibrated_single_inhos, prefix=\"single_inhos_snuh\")\n",
        "plot_calibration_curve_with_ci2(aya_nowon0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_nowon_pred4, prefix=\"single_inhos_nowon\")\n",
        "plot_calibration_curve_with_ci2(aya_kmc0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_kmc_pred4, prefix=\"single_inhos_kmc\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqs_eOaJ9tuV"
      },
      "outputs": [],
      "source": [
        "# Spline calibration for in hospital mortality\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bins_count = len(fraction_of_positives)\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(bins_count):\n",
        "        bin_low = bin_edges[i]\n",
        "        bin_high = bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {bins_count})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_single_inhos = splinecalib.predict(single_inhos)\n",
        "calibrated_aya_nowon_pred4 = splinecalib.predict(aya_nowon_pred4)\n",
        "calibrated_aya_kmc_pred4 = splinecalib.predict(aya_kmc_pred4)\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test0.iloc[:, [0]].to_numpy().flatten(), calibrated_single_inhos)\n",
        "plot_calibration_curve_with_ci2(aya_nowon0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_nowon_pred4)\n",
        "plot_calibration_curve_with_ci2(aya_kmc0.iloc[:, [0]].to_numpy().flatten(), calibrated_aya_kmc_pred4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bc2249a-4829-4816-8017-4cbdeb8ab3c3"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92c7eff1-c02b-49b8-9103-3b39e869984a"
      },
      "source": [
        "# 4. Multi-Task GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4743276e-11ca-48f3-b33c-2135041d086b"
      },
      "outputs": [],
      "source": [
        "def mtgbm3_kmc(lgbmmt3_model_d, dkmc, y1_kmc):\n",
        "    features = [x for x in dkmc.columns]\n",
        "    y_lgbmtsub = np.zeros((dkmc.shape[0], 3))\n",
        "    temp = lgbmmt3_model_d.predict(dkmc[features])\n",
        "    y_lgbmtsub += (1. / (1. + np.exp(-temp)))\n",
        "    return y_lgbmtsub\n",
        "\n",
        "def self_metric3(preds, train_data):\n",
        "    labels = train_data.get_label()\n",
        "    labels2 = labels.reshape((num_labels, -1)).transpose()\n",
        "    preds2 = preds.reshape((num_labels, -1)).transpose()\n",
        "    auroc_scores = []\n",
        "    for i in [0, 1, 2]:\n",
        "        labels_binary = labels2[:, i]\n",
        "        preds_binary = 1. / (1. + np.exp(-preds2[:, i]))\n",
        "        auroc_score = roc_auc_score(labels_binary, preds_binary)\n",
        "        auroc_scores.append(round(auroc_score, 3))\n",
        "    score_dict = {\n",
        "        'auroc1': auroc_scores[0],\n",
        "        'auroc2': auroc_scores[1],\n",
        "        'auroc3': auroc_scores[2],\n",
        "    }\n",
        "    return [('auroc1', score_dict['auroc1'], True),\n",
        "            ('auroc2', score_dict['auroc2'], True),\n",
        "            ('auroc3', score_dict['auroc3'], True)]\n",
        "\n",
        "def calculate_gradient(li, pi):\n",
        "    gradient = -1 * (li - pi)\n",
        "    return gradient\n",
        "\n",
        "def calculate_hessian(li, pi):\n",
        "    hessian = np.full_like(pi, 1.0)\n",
        "    return hessian\n",
        "\n",
        "def f(corr, weights):\n",
        "    return np.sum(corr * weights)\n",
        "\n",
        "def clip_corr(corr):\n",
        "    return np.clip(corr, 0.1, 1)\n",
        "\n",
        "def calculate_beta(epoch):\n",
        "    max_beta = 0.4\n",
        "    min_beta = 0.2\n",
        "    decay_rate = 0.5\n",
        "    decay_steps = 100\n",
        "    current_step = epoch % decay_steps\n",
        "    beta = max_beta - decay_rate * (current_step // (decay_steps / 2))\n",
        "    beta = np.maximum(min_beta, beta)\n",
        "    return beta\n",
        "\n",
        "def apply_threshold(predictions, threshold):\n",
        "    return (predictions > threshold).astype(int)\n",
        "\n",
        "def mymse3(preds, train_data, ep=0):\n",
        "    labels = train_data.get_label()\n",
        "    labels2 = labels.reshape((num_labels, -1)).transpose()\n",
        "    preds2 = preds.reshape((num_labels, -1)).transpose()\n",
        "    labels2 = np.clip(labels2, 0, 1)\n",
        "    preds3 = 1. / (1. + np.exp(-preds2))\n",
        "    grad2 = preds3 - labels2\n",
        "    hess2 = preds3 * (1. - preds3)\n",
        "    beta = 0.2\n",
        "    w = np.array([1, 1, 0.01 * beta])\n",
        "    w2 = np.array([1.0, 1.0, 1.0])\n",
        "    grad = (grad2) * np.array(w)\n",
        "    grad = np.sum(grad, axis=1)\n",
        "    grad2 = (grad2 * w2).transpose().reshape((-1))\n",
        "    hess = np.sum((hess2) * np.array(w), axis=1)\n",
        "    return grad, hess, grad2, hess2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBtC391fsun_"
      },
      "source": [
        "# Hyper Parameter for MTGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "698278ad"
      },
      "outputs": [],
      "source": [
        "pa_0115 = {\n",
        "    'objective': 'custom',\n",
        "    'num_labels': 3,\n",
        "    'tree_learner': 'serial2',\n",
        "    'boosting': 'gbdt',\n",
        "    'max_depth': 16,\n",
        "    'learning_rate': 0.01,\n",
        "    'bagging_fraction': 0.7,\n",
        "    'feature_fraction': 0.7,\n",
        "    'verbosity': -1,\n",
        "    'lambda_l1': 0.7,\n",
        "    'lambda_l2': 0.7,\n",
        "    'num_leaves': 50,\n",
        "    'min_child_weight': 0.3,\n",
        "    'min_data_in_leaf': 40,\n",
        "    'metric_freq': 9,\n",
        "    'data_random_seed': SEED,\n",
        "    'num_threads': -1,\n",
        "    'num_boost_round': 600\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed35deab-3d10-415e-96ca-14981e5972de"
      },
      "outputs": [],
      "source": [
        "def MTGBM_3TASK(folds_features, folds_targets, features, dtest, y3_test, lgbmmt3_params2, cate):\n",
        "    subtasklist = [x for x in y3_test.columns]\n",
        "    featuresall = [x for x in dtest.columns]\n",
        "    foldsn = FOLDS_NUM\n",
        "    y_lgbmt = np.zeros((dtest.shape[0], num_labels))\n",
        "    y_lgbmtsub = np.zeros((dtest.shape[0], num_labels))\n",
        "    sub_task = [1, 2]\n",
        "    best_thresholds = [[0.0, 0.0, 0.0]]\n",
        "\n",
        "    for i in range(foldsn):\n",
        "        X_vl, y_vl = folds_features[i][features], folds_targets[i]['total_aki']\n",
        "        X_tr = pd.concat([folds_features[j] for j in range(foldsn) if j != i], axis=0)[features]\n",
        "        y_tr = pd.concat([folds_targets[j] for j in range(foldsn) if j != i], axis=0)['total_aki']\n",
        "        y_tr2 = pd.concat([folds_targets[j] for j in range(foldsn) if j != i], axis=0).iloc[:, sub_task]\n",
        "        y_vl2 = folds_targets[i].iloc[:, sub_task]\n",
        "        y_oof = np.zeros((X_vl.shape[0], num_labels))\n",
        "\n",
        "        k_train = lgbmmt.Dataset(X_tr, label=np.concatenate([y_tr.values.reshape((-1, 1)), y_tr2.values], axis=1), categorical_feature=cate)\n",
        "        k_valid = lgbmmt.Dataset(X_vl, label=np.concatenate([y_vl.values.reshape((-1, 1)), y_vl2.values], axis=1), categorical_feature=cate)\n",
        "        watchlist = [k_valid]\n",
        "\n",
        "        lgbmmt3_model = lgbmmt.train(\n",
        "            lgbmmt3_params2,\n",
        "            train_set=k_train,\n",
        "            valid_sets=watchlist,\n",
        "            verbose_eval=100,\n",
        "            fobj=mymse3,\n",
        "            feval=self_metric3,\n",
        "        )\n",
        "\n",
        "        lgbmmt3_model.set_num_labels(num_labels)\n",
        "\n",
        "        y_pred_train = lgbmmt3_model.predict(X_vl)\n",
        "        y_oof = y_pred_train\n",
        "\n",
        "        y_pred_valid = mtgbm3_kmc(lgbmmt3_model, X_vl, np.concatenate([y_vl.values.reshape((-1, 1)), y_vl2.values], axis=1))\n",
        "        print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train[:, 0])))\n",
        "        print('ROC AUC {}'.format(roc_auc_score(y_vl2.iloc[:, 0], y_pred_train[:, 1])))\n",
        "        print('ROC AUC {}'.format(roc_auc_score(y_vl2.iloc[:, 1], y_pred_train[:, 2])))\n",
        "\n",
        "        temp = lgbmmt3_model.predict(dtest[features])\n",
        "        i += 1\n",
        "\n",
        "    dtrain = pd.concat([folds_features[j] for j in range(foldsn)], axis=0)[features]\n",
        "    y3_train = pd.concat([folds_targets[j] for j in range(foldsn)], axis=0)\n",
        "    bayes_dtrain = lgbmmt.Dataset(dtrain, label=y3_train.to_numpy(), categorical_feature=cate)\n",
        "    bayes_dtest = lgbmmt.Dataset(dtest, label=y3_test.to_numpy(), categorical_feature=cate)\n",
        "\n",
        "    lgbmmt3_model = lgbmmt.train(\n",
        "        lgbmmt3_params2,\n",
        "        train_set=bayes_dtrain,\n",
        "        verbose_eval=100,\n",
        "        fobj=mymse3,\n",
        "        feval=self_metric3,\n",
        "    )\n",
        "\n",
        "    lgbmmt3_model.set_num_labels(num_labels)\n",
        "\n",
        "    fortmp = lgbmmt3_model.predict(dtrain[features])\n",
        "    forthval = (1. / (1. + np.exp(-fortmp)))\n",
        "\n",
        "    best_thresholds[0][0] = new_threshold(y3_train.iloc[:, 0], forthval[:, 0])\n",
        "    best_thresholds[0][1] = new_threshold(y3_train.iloc[:, 1], forthval[:, 1])\n",
        "    best_thresholds[0][2] = new_threshold(y3_train.iloc[:, 2], forthval[:, 2])\n",
        "\n",
        "    tmp = lgbmmt3_model.predict(dtest[features])\n",
        "    y_lgbmtsub = (1. / (1. + np.exp(-tmp)))\n",
        "\n",
        "    return y_lgbmtsub, lgbmmt3_model, best_thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrR3rVRISP3e"
      },
      "outputs": [],
      "source": [
        "folds_targets3 = [df.drop(df.columns[1], axis=1) for df in folds_targets]\n",
        "folds_targets3[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae2m3xtzUTwO"
      },
      "outputs": [],
      "source": [
        "aya_test03 = aya_test0.drop(aya_test0.columns[1], axis=1)\n",
        "aya_test03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c82ac5f3-f87a-491b-a795-a36fe97e94ad"
      },
      "outputs": [],
      "source": [
        "#MTGBM\n",
        "cate = []\n",
        "\n",
        "y_pred, model, mt_thold = MTGBM_3TASK(folds_features, folds_targets3, ft0, adtest0[ft0], aya_test03, pa_0115, cate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc66mX2bZQoi"
      },
      "outputs": [],
      "source": [
        "aya_nowon03 = aya_nowon0.drop(aya_nowon0.columns[1], axis=1)\n",
        "aya_kmc03 = aya_kmc0.drop(aya_kmc0.columns[1], axis=1)\n",
        "aya_nowon03, aya_kmc03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7df16459-3b88-4df3-8618-21aa11b9438f"
      },
      "outputs": [],
      "source": [
        "y_pred_sub_n = mtgbm3_kmc(model,  adnowon0[ft0], aya_nowon03)\n",
        "y_pred_sub_k = mtgbm3_kmc(model,  adkmc0[ft0], aya_kmc03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efbd7722-9b69-4722-8ac9-7928a288ecee"
      },
      "outputs": [],
      "source": [
        "# SNU\n",
        "asa_test0.loc[asa_test0['asa'] == 6, 'asa'] = 1\n",
        "asa_test0['asa'] = np.nan_to_num(asa_test0['asa'], nan=2)\n",
        "scaler = MinMaxScaler()\n",
        "asa_reshaped = asa_test0['asa'].values.reshape(-1, 1)\n",
        "asa_scaled = asa_reshaped / 5\n",
        "print(np.unique(asa_scaled))\n",
        "\n",
        "# Nowon\n",
        "asa_nowon0['asa'] = np.nan_to_num(asa_nowon0['asa'], nan=2)\n",
        "scaler = MinMaxScaler()\n",
        "asa_reshaped_n = asa_nowon0['asa'].values.reshape(-1, 1)\n",
        "asa_scaled_n = asa_reshaped_n / 5\n",
        "print(np.unique(asa_scaled_n))\n",
        "\n",
        "# KMC\n",
        "asa_kmc0['asa'] = np.nan_to_num(asa_kmc0['asa'], nan=2)\n",
        "scaler = MinMaxScaler()\n",
        "asa_reshaped_k = asa_kmc0['asa'].values.reshape(-1, 1)\n",
        "asa_scaled_k = asa_reshaped_k / 5\n",
        "print(np.unique(asa_scaled_k))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df57692c-f29b-4237-801b-b88f822b26a0"
      },
      "outputs": [],
      "source": [
        "# SNU Delong\n",
        "print(\"delong pvalue SNU_aki_/ single vs asa:\")\n",
        "delong_roc_test(aya_test0.iloc[:, [0]].astype(int).to_numpy().flatten(), single_aki, asa_scaled.flatten())\n",
        "print(\"delong pvalue SNU_aki_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_test0.iloc[:, [0]].astype(int).to_numpy().flatten(), y_pred[:, 0:1].flatten(), asa_scaled.flatten())\n",
        "\n",
        "print(\"delong pvalue SNU_prf_/ single vs asa:\")\n",
        "delong_roc_test(aya_test0.iloc[:, [2]].astype(int).to_numpy().flatten(), single_prf, asa_scaled.flatten())\n",
        "print(\"delong pvalue SNU_prf_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_test0.iloc[:, [2]].astype(int).to_numpy().flatten(), y_pred[:, 1:2].flatten(), asa_scaled.flatten())\n",
        "\n",
        "print(\"delong pvalue SNU_inhos_/ single vs asa:\")\n",
        "delong_roc_test(aya_test0.iloc[:, [3]].astype(int).to_numpy().flatten(), single_inhos, asa_scaled.flatten())\n",
        "print(\"delong pvalue SNU_inhos_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_test0.iloc[:, [3]].astype(int).to_numpy().flatten(), y_pred[:, 2:3].flatten(), asa_scaled.flatten())\n",
        "\n",
        "# Nowon Delong\n",
        "print(\"delong pvalue nowon_aki_/ single vs asa:\")\n",
        "delong_roc_test(aya_nowon0.iloc[:, [0]].astype(int).to_numpy().flatten(), aya_nowon_pred, asa_scaled_n.flatten())\n",
        "print(\"delong pvalue nowon_aki_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_nowon0.iloc[:, [0]].astype(int).to_numpy().flatten(), y_pred_sub_n[:, 0:1].flatten(), asa_scaled_n.flatten())\n",
        "\n",
        "print(\"delong pvalue nowon_prf_/ single vs asa:\")\n",
        "delong_roc_test(aya_nowon0.iloc[:, [2]].astype(int).to_numpy().flatten(), aya_nowon_pred3, asa_scaled_n.flatten())\n",
        "print(\"delong pvalue nowon_prf_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_nowon0.iloc[:, [2]].astype(int).to_numpy().flatten(), y_pred_sub_n[:, 1:2].flatten(), asa_scaled_n.flatten())\n",
        "\n",
        "print(\"delong pvalue nowon_inhos_/ single vs asa:\")\n",
        "delong_roc_test(aya_nowon0.iloc[:, [3]].astype(int).to_numpy().flatten(), aya_nowon_pred4, asa_scaled_n.flatten())\n",
        "print(\"delong pvalue nowon_inhos_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_nowon0.iloc[:, [3]].astype(int).to_numpy().flatten(), y_pred_sub_n[:, 2:3].flatten(), asa_scaled_n.flatten())\n",
        "\n",
        "# KMC Delong\n",
        "print(\"delong pvalue kmc_aki_/ single vs asa:\")\n",
        "delong_roc_test(aya_kmc0.iloc[:, [0]].astype(int).to_numpy().flatten(), aya_kmc_pred, asa_scaled_k.flatten())\n",
        "print(\"delong pvalue kmc_aki_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_kmc0.iloc[:, [0]].astype(int).to_numpy().flatten(), y_pred_sub_k[:, 0:1].flatten(), asa_scaled_k.flatten())\n",
        "\n",
        "print(\"delong pvalue kmc_prf_/ single vs asa:\")\n",
        "delong_roc_test(aya_kmc0.iloc[:, [2]].astype(int).to_numpy().flatten(), aya_kmc_pred3, asa_scaled_k.flatten())\n",
        "print(\"delong pvalue kmc_prf_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_kmc0.iloc[:, [2]].astype(int).to_numpy().flatten(), y_pred_sub_k[:, 1:2].flatten(), asa_scaled_k.flatten())\n",
        "\n",
        "print(\"delong pvalue kmc_inhos_/ single vs asa:\")\n",
        "delong_roc_test(aya_kmc0.iloc[:, [3]].astype(int).to_numpy().flatten(), aya_kmc_pred4, asa_scaled_k.flatten())\n",
        "print(\"delong pvalue kmc_inhos_/ mtgbm vs asa:\")\n",
        "delong_roc_test(aya_kmc0.iloc[:, [3]].astype(int).to_numpy().flatten(), y_pred_sub_k[:, 2:3].flatten(), asa_scaled_k.flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2d9a319-a5dc-4370-955f-c203ff45e638"
      },
      "outputs": [],
      "source": [
        "fpr_aki, tpr_aki, _ = roc_curve(aya_test03.iloc[:, 0], single_aki)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_test03.iloc[:, 0], y_pred[:, 0])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison _ aki _snu')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_aki_snu.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ong0r_6rOrpR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "mpl.rcParams['figure.facecolor'] = 'white'\n",
        "mpl.rcParams['axes.facecolor'] = 'white'\n",
        "mpl.rcParams['axes.edgecolor'] = 'black'\n",
        "mpl.rcParams['axes.labelcolor'] = 'black'\n",
        "mpl.rcParams['axes.linewidth'] = 1.0\n",
        "mpl.rcParams['font.family'] = 'serif'\n",
        "mpl.rcParams['font.size'] = 12\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "mpl.rcParams['xtick.color'] = 'black'\n",
        "mpl.rcParams['ytick.color'] = 'black'\n",
        "mpl.rcParams['xtick.labelsize'] = 11\n",
        "mpl.rcParams['ytick.labelsize'] = 11\n",
        "mpl.rcParams['legend.frameon'] = False\n",
        "mpl.rcParams['savefig.dpi'] = 300\n",
        "\n",
        "plt.figure(figsize=(6.5, 5))\n",
        "plt.plot(\n",
        "    fpr_mt, tpr_mt,\n",
        "    color='navy', lw=2,\n",
        "    label=f'MT-GBM Model (AUC = {roc_auc_mt_str})'\n",
        ")\n",
        "plt.plot(\n",
        "    fpr_aki, tpr_aki,\n",
        "    color='darkorange', lw=2,\n",
        "    label=f'Single Prediction Model (AUC = {roc_auc_aki_str})'\n",
        ")\n",
        "plt.plot(\n",
        "    [0, 1], [0, 1],\n",
        "    color='gray', lw=1.5, linestyle='--'\n",
        ")\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.02])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison for AKI Prediction', fontsize=14, pad=10)\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "820aa9c3-e952-403b-8bca-1e0e9bf76645"
      },
      "outputs": [],
      "source": [
        "fpr_aki, tpr_aki, _ = roc_curve(aya_nowon03.iloc[:, 0], aya_nowon_pred)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_nowon03.iloc[:, 0], y_pred_sub_n[:, 0])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison aki nowon')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_aki_nowon.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffe45f05-cbac-440e-aa42-71e4b4811751"
      },
      "outputs": [],
      "source": [
        "fpr_aki, tpr_aki, _ = roc_curve(aya_kmc03.iloc[:, 0], aya_kmc_pred)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_kmc03.iloc[:, 0], y_pred_sub_k[:, 0])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison aki_kmc')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_aki_kmc.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f48bff51-0601-4684-a737-87275af4318a"
      },
      "outputs": [],
      "source": [
        "#prf snu\n",
        "fpr_prf, tpr_prf, _ = roc_curve(aya_test03.iloc[:, 1], single_prf)\n",
        "roc_auc_prf = auc(fpr_prf, tpr_prf)\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_test03.iloc[:, 1], y_pred[:, 1])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_prf_str = f'{roc_auc_prf:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_prf, tpr_prf, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_prf_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison prf _ snu')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_prf_snu.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "214137fb-a407-4743-99ec-a078e1e60a14"
      },
      "outputs": [],
      "source": [
        "# prf nowon\n",
        "fpr_aki, tpr_aki, _ = roc_curve(aya_nowon03.iloc[:, 1], aya_nowon_pred3)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_nowon03.iloc[:, 1], y_pred_sub_n[:, 1])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison prf nowon')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_prf_nowon.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1339506-7ea5-4b03-b333-ee74f86036cd"
      },
      "outputs": [],
      "source": [
        "# prf kmc\n",
        "fpr_aki, tpr_aki, _ = roc_curve(aya_kmc03.iloc[:, 1], aya_kmc_pred3)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_kmc03.iloc[:, 1], y_pred_sub_k[:, 1])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison prf_kmc')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_prf_kmc.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e2b5d04-05d5-4f4f-9c29-2cccc85238e7"
      },
      "outputs": [],
      "source": [
        "#inhos snu\n",
        "fpr_inhos, tpr_inhos, _ = roc_curve(aya_test03.iloc[:, 2], single_inhos)\n",
        "roc_auc_inhos = auc(fpr_inhos, tpr_inhos)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_test03.iloc[:, 2], y_pred[:, 2])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_inhos_str = f'{roc_auc_inhos:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_inhos, tpr_inhos, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_inhos_str})')\n",
        "# plt.plot(fpr_asa, tpr_asa, color='green', lw=2, label=f'ASA class (AUC = {roc_auc_asa_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison inhos snu')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_inhos_mortality_snu.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dae56ba-7725-4feb-943b-2f031a989f88"
      },
      "outputs": [],
      "source": [
        "# inhos nowon\n",
        "fpr_aki, tpr_aki, _ = roc_curve(aya_nowon03.iloc[:, 2], aya_nowon_pred4)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_nowon03.iloc[:, 2], y_pred_sub_n[:, 2])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison inhos nowon')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_inhos_mortality_nowon.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "875d0657-cf11-4af0-bb62-7a9dccf9b950"
      },
      "outputs": [],
      "source": [
        "# inhos kmc\n",
        "fpr_aki, tpr_aki, _ = roc_curve(aya_kmc03.iloc[:, 2], aya_kmc_pred4)\n",
        "roc_auc_aki = auc(fpr_aki, tpr_aki)\n",
        "\n",
        "fpr_mt, tpr_mt, _ = roc_curve(aya_kmc03.iloc[:, 2], y_pred_sub_k[:, 2])\n",
        "roc_auc_mt = auc(fpr_mt, tpr_mt)\n",
        "\n",
        "roc_auc_aki_str = f'{roc_auc_aki:.4f}'\n",
        "roc_auc_mt_str = f'{roc_auc_mt:.4f}'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_mt, tpr_mt, color='navy', lw=2, label=f'MT-GBM Model (AUC = {roc_auc_mt_str})')\n",
        "plt.plot(fpr_aki, tpr_aki, color='darkorange', lw=2, label=f'Single Prediction Model (AUC = {roc_auc_aki_str})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison inhos_kmc')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve_comparison_inhos_mortality_kmc.jpg', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llbxUkdthXoB"
      },
      "outputs": [],
      "source": [
        "#snu ci calibration\n",
        "plot_calibration_curve_with_ci2(aya_test03.iloc[:, [0]].to_numpy().flatten(), y_pred[:, 0:1].flatten())\n",
        "#nowon ci calibration\n",
        "plot_calibration_curve_with_ci2(aya_nowon03.iloc[:, [0]].to_numpy().flatten(),  y_pred_sub_n[:, 0:1].flatten())\n",
        "#kmc ci calibration\n",
        "plot_calibration_curve_with_ci2(aya_kmc03.iloc[:, [0]].to_numpy().flatten(),  y_pred_sub_k[:, 0:1].flatten())\n",
        "\n",
        "#delong\n",
        "print(\"delong pvalue SNU:\")\n",
        "delong_roc_test(aya_test03.iloc[:, [0]].astype(int).to_numpy().flatten(),  single_aki,  y_pred[:, 0:1].flatten() )\n",
        "print(\"delong pvalue nowon:\")\n",
        "delong_roc_test(aya_nowon03.iloc[:, [0]].astype(int).to_numpy().flatten() , aya_nowon_pred, y_pred_sub_n[:, 0:1].flatten())\n",
        "print(\"delong pvalue KMC:\")\n",
        "delong_roc_test(aya_kmc03.iloc[:, [0]].astype(int).to_numpy().flatten() , aya_kmc_pred, y_pred_sub_k[:, 0:1].flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Yo3_gME6AmI"
      },
      "outputs": [],
      "source": [
        "# Spline calibration for AKI of MTGBM\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95, prefix=None):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        bin_low, bin_high = bin_edges[i], bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {n_bins})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if prefix is not None:\n",
        "        plt.savefig(f\"{prefix}_calibration_curve.png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_y_pred = splinecalib.predict(y_pred[:, 0:1].flatten())\n",
        "calibrated_y_pred_sub_n = splinecalib.predict(y_pred_sub_n[:, 0:1].flatten())\n",
        "calibrated_y_pred_sub_k = splinecalib.predict(y_pred_sub_k[:, 0:1].flatten())\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred, prefix=\"mtgbm_snu_aki\")\n",
        "plot_calibration_curve_with_ci2(aya_nowon03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred_sub_n, prefix=\"mtgbm_nowon_aki\")\n",
        "plot_calibration_curve_with_ci2(aya_kmc03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred_sub_k, prefix=\"mtgbm_kmc_aki\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaMKE7P76j9k"
      },
      "outputs": [],
      "source": [
        "## SPline calibration for PRF of MTGBM\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95, prefix=None):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bins_length = len(fraction_of_positives)\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(bins_length):\n",
        "        bin_low = bin_edges[i]\n",
        "        bin_high = bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {bins_length})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if prefix is not None:\n",
        "        plt.savefig(f\"{prefix}_calibration_curve.png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_y_pred = splinecalib.predict(y_pred[:, 1:2].flatten())\n",
        "calibrated_y_pred_sub_n = splinecalib.predict(y_pred_sub_n[:, 1:2].flatten())\n",
        "calibrated_y_pred_sub_k = splinecalib.predict(y_pred_sub_k[:, 1:2].flatten())\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred, prefix=\"mtgbm_snu_prf\")\n",
        "plot_calibration_curve_with_ci2(aya_nowon03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred_sub_n, prefix=\"mtgbm_nowon_prf\")\n",
        "plot_calibration_curve_with_ci2(aya_kmc03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred_sub_k, prefix=\"mtgbm_kmc_prf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEHtV_5k7AFb"
      },
      "outputs": [],
      "source": [
        "# Spline calibration for inhos mortality of MTGBM\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "def plot_calibration_curve_with_ci2(actual_labels, predicted_probabilities, n_bins=9, confidence=0.95, prefix=None):\n",
        "    actual_labels = np.array(actual_labels)\n",
        "    predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        actual_labels, predicted_probabilities, n_bins=n_bins, strategy='uniform'\n",
        "    )\n",
        "\n",
        "    bins_length = len(fraction_of_positives)\n",
        "    bin_edges = np.linspace(0, 1, n_bins + 1)\n",
        "    z = 1.96\n",
        "\n",
        "    x_values = []\n",
        "    y_values = []\n",
        "    y_err = []\n",
        "\n",
        "    for i in range(bins_length):\n",
        "        bin_low = bin_edges[i]\n",
        "        bin_high = bin_edges[i+1]\n",
        "        mask = (predicted_probabilities >= bin_low) & (predicted_probabilities < bin_high)\n",
        "        n = np.sum(mask)\n",
        "        y = fraction_of_positives[i]\n",
        "        x = mean_predicted_value[i]\n",
        "\n",
        "        if n > 0:\n",
        "            std_err = np.sqrt(y * (1 - y) / n)\n",
        "            h = std_err * z\n",
        "        else:\n",
        "            h = 0\n",
        "\n",
        "        x_values.append(x)\n",
        "        y_values.append(y)\n",
        "        y_err.append(h)\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.errorbar(\n",
        "        x_values, y_values, yerr=y_err, fmt='o', color='tab:blue', ecolor='gray',\n",
        "        capsize=4, markersize=7, linewidth=2, alpha=0.5, label=\"Spline Calibration\"\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', linewidth=2, label=\"Perfect Calibration\")\n",
        "    plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Fraction of Positives\", fontsize=14)\n",
        "    plt.title(f\"Spline-Scaled Calibration Curve with 95% CI (Bins: {bins_length})\", fontsize=16)\n",
        "    plt.xlim(0.0, 1.0)\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(predicted_probabilities, bins=20, alpha=0.7, color='tab:blue', edgecolor='black')\n",
        "    plt.xlabel(\"Calibrated Probability\", fontsize=14)\n",
        "    plt.ylabel(\"Count\", fontsize=14)\n",
        "    plt.title(\"Calibrated Probability Distribution\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if prefix is not None:\n",
        "        plt.savefig(f\"{prefix}_calibration_curve.png\", dpi=300)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "splinecalib = mli.SplineCalib()\n",
        "splinecalib.fit(forthval, y1_train)\n",
        "\n",
        "calibrated_y_pred = splinecalib.predict(y_pred[:, 2:3].flatten())\n",
        "calibrated_y_pred_sub_n = splinecalib.predict(y_pred_sub_n[:, 2:3].flatten())\n",
        "calibrated_y_pred_sub_k = splinecalib.predict(y_pred_sub_k[:, 2:3].flatten())\n",
        "\n",
        "plot_calibration_curve_with_ci2(aya_test03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred, prefix=\"mtgbm_snu_inhos\")\n",
        "plot_calibration_curve_with_ci2(aya_nowon03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred_sub_n, prefix=\"mtgbm_nowon_inhos\")\n",
        "plot_calibration_curve_with_ci2(aya_kmc03.iloc[:, [0]].to_numpy().flatten(), calibrated_y_pred_sub_k, prefix=\"mtgbm_kmc_inhos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JasaenTeha4m"
      },
      "outputs": [],
      "source": [
        "print(\"AKI - delong pvalue SNU:\")\n",
        "delong_roc_test(aya_test03.iloc[:, [0]].astype(int).to_numpy().flatten(),  single_aki,  y_pred[:, 0:1].flatten() )\n",
        "print(\"AKI - delong pvalue nowon:\")\n",
        "delong_roc_test(aya_nowon03.iloc[:, [0]].astype(int).to_numpy().flatten() , aya_nowon_pred, y_pred_sub_n[:, 0:1].flatten())\n",
        "print(\"AKI - delong pvalue KMC:\")\n",
        "delong_roc_test(aya_kmc03.iloc[:, [0]].astype(int).to_numpy().flatten() , aya_kmc_pred, y_pred_sub_k[:, 0:1].flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "147cef4d-ba30-4cfd-96fd-2603f7752065"
      },
      "outputs": [],
      "source": [
        "print(\"PRF - delong pvalue SNU_prf:\")\n",
        "delong_roc_test(aya_test03.iloc[:, [1]].astype(int).to_numpy().flatten(),  single_prf,  y_pred[:, 1:2].flatten() )\n",
        "print(\"PRF - delong pvalue nowon_prf:\")\n",
        "delong_roc_test(aya_nowon03.iloc[:, [1]].astype(int).to_numpy().flatten() , aya_nowon_pred3, y_pred_sub_n[:, 1:2].flatten())\n",
        "print(\"PRF - delong pvalue KMC_prf:\")\n",
        "delong_roc_test(aya_kmc03.iloc[:, [1]].astype(int).to_numpy().flatten() , aya_kmc_pred3, y_pred_sub_k[:, 1:2].flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3824117-7798-4fcd-ba0c-00c7fbb17111"
      },
      "outputs": [],
      "source": [
        "print(\"Inhos mortality - delong pvalue SNU_inhos:\")\n",
        "delong_roc_test(aya_test03.iloc[:, [2]].astype(int).to_numpy().flatten(),  single_inhos,  y_pred[:, 2:3].flatten() )\n",
        "print(\"Inhos mortality - delong pvalue nowon_inhos:\")\n",
        "delong_roc_test(aya_nowon03.iloc[:, [2]].astype(int).to_numpy().flatten() , aya_nowon_pred4, y_pred_sub_n[:, 2:3].flatten())\n",
        "print(\"Inhos mortality - delong pvalue KMC_inhos:\")\n",
        "delong_roc_test(aya_kmc03.iloc[:, [2]].astype(int).to_numpy().flatten() , aya_kmc_pred4, y_pred_sub_k[:, 2:3].flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "158f0a02-a9c7-4b35-85b8-64fcc4d6bdb3"
      },
      "outputs": [],
      "source": [
        "val_mt1_aki = auc_plot(aya_test03.iloc[:, [0]], y_pred[:, 0:1], 'mt_total_aki_snu' ,mt_thold[0][0])\n",
        "val_mt1_aki_n =auc_plot(aya_nowon03.iloc[:, [0]], y_pred_sub_n[:, 0:1],  'mt_total_aki_nowon',mt_thold[0][0])\n",
        "val_mt1_aki_k =auc_plot(aya_kmc03.iloc[:, [0]], y_pred_sub_k[:, 0:1],  'mt_total_aki_kmc',mt_thold[0][0])\n",
        "\n",
        "val_mt1_prf = auc_plot(aya_test03.iloc[:, [1]],  y_pred[:, 1:2], 'mt_total_prf_snu',mt_thold[0][1])\n",
        "val_mt1_prf_n =auc_plot(aya_nowon03.iloc[:, [1]], y_pred_sub_n[:, 1:2],  'mt_total_prf_nowon',mt_thold[0][1])\n",
        "val_mt1_prf_k =auc_plot(aya_kmc03.iloc[:, [1]],  y_pred_sub_k[:, 1:2],  'mt_total_prf_kmc',mt_thold[0][1])\n",
        "\n",
        "val_mt1_inhos = auc_plot(aya_test03.iloc[:, [2]],  y_pred[:, 2:3], 'mt_total_inhos_snu',mt_thold[0][2])\n",
        "val_mt1_inhos_n =auc_plot(aya_nowon03.iloc[:, [2]], y_pred_sub_n[:, 2:3],  'mt_total_inhos_nowon',mt_thold[0][2])\n",
        "val_mt1_inhos_k =auc_plot(aya_kmc03.iloc[:, [2]],  y_pred_sub_k[:, 2:3], 'mt_total_inhos_kmc',mt_thold[0][2])\n",
        "\n",
        "result = pd.concat([result, val_mt1_aki])\n",
        "result = pd.concat([result, val_mt1_aki_n])\n",
        "result = pd.concat([result, val_mt1_aki_k])\n",
        "\n",
        "result = pd.concat([result, val_mt1_prf])\n",
        "result = pd.concat([result, val_mt1_prf_n])\n",
        "result = pd.concat([result, val_mt1_prf_k])\n",
        "\n",
        "result = pd.concat([result, val_mt1_inhos])\n",
        "result = pd.concat([result, val_mt1_inhos_n])\n",
        "result = pd.concat([result, val_mt1_inhos_k])\n",
        "\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
